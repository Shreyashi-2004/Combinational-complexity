{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ce308ff-5d45-4e13-8276-c2ed5eccc0a0",
   "metadata": {},
   "source": [
    "## Dataset Creation  \n",
    "- This section creates a dataset to predict the combinational depth of signals.  \n",
    "- The dataset includes key RTL parameters such as:  \n",
    "  - Fan-In and Fan-Out  \n",
    "  - Gate Count  \n",
    "  - Gate Types  \n",
    "  - Combinational Logic Depth (target variable)  \n",
    "- The data is structured to simulate real-world RTL timing reports.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23683339-ccf7-4107-89e7-1e78070f47d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fan-In Distribution:\n",
      "Fan-In\n",
      "2      31\n",
      "3      42\n",
      "4      66\n",
      "5      89\n",
      "6     113\n",
      "7      87\n",
      "8      42\n",
      "9      18\n",
      "10      8\n",
      "11      2\n",
      "12      2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Fan-Out Distribution:\n",
      "Fan-Out\n",
      "1     79\n",
      "2     92\n",
      "3     91\n",
      "4     76\n",
      "5     47\n",
      "6     38\n",
      "7     35\n",
      "8     18\n",
      "9      9\n",
      "10    15\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Gate Count Distribution:\n",
      "Gate Count\n",
      "1      2\n",
      "2     12\n",
      "3     22\n",
      "4     34\n",
      "5     35\n",
      "6     35\n",
      "7     28\n",
      "8     40\n",
      "9     41\n",
      "10    42\n",
      "11    25\n",
      "12    29\n",
      "13    24\n",
      "14    14\n",
      "15    16\n",
      "16    18\n",
      "17    14\n",
      "18    11\n",
      "19     8\n",
      "20     5\n",
      "21     5\n",
      "22     5\n",
      "23     6\n",
      "24     3\n",
      "25     2\n",
      "26     6\n",
      "27     4\n",
      "28     3\n",
      "29     3\n",
      "30     8\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Logic Depth Distribution:\n",
      "Logic Depth\n",
      "2    102\n",
      "3    122\n",
      "4    110\n",
      "5     86\n",
      "6     41\n",
      "7     24\n",
      "8     15\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First 5 Rows:\n",
      "        Module Name Signal Name  Fan-In  Fan-Out  Gate Count  Logic Depth  \\\n",
      "0  synthetic_module           y       9       10           9            2   \n",
      "1  synthetic_module           y       6        6          10            3   \n",
      "2  synthetic_module           y       8        7           9            2   \n",
      "3  synthetic_module           y       8        3          14            3   \n",
      "4  synthetic_module           y       3        6           4            2   \n",
      "\n",
      "  Gate Types  \n",
      "0  AND, NAND  \n",
      "1  AND, NAND  \n",
      "2  AND, NAND  \n",
      "3  AND, NAND  \n",
      "4        AND  \n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def weighted_choice(weights):\n",
    "    \"\"\" Returns a value based on given probability distribution \"\"\"\n",
    "    keys, probabilities = zip(*weights.items())\n",
    "    probabilities = np.array(probabilities) / sum(probabilities)  \n",
    "    return np.random.choice(keys, p=probabilities)\n",
    "\n",
    "def generate_random_expression(inputs, depth):\n",
    "    \"\"\" Generate a random logic expression with given depth. \"\"\"\n",
    "    if depth == 1:\n",
    "        return random.choice(inputs)\n",
    "    else:\n",
    "        gate = random.choice([\"AND\", \"OR\", \"NOT\", \"NAND\", \"NOR\", \"XOR\"])\n",
    "        if gate == \"NOT\":\n",
    "            return f\"~({generate_random_expression(inputs, depth - 1)})\"\n",
    "        else:\n",
    "            return f\"({generate_random_expression(inputs, depth - 1)} {gate} {generate_random_expression(inputs, depth - 1)})\"\n",
    "\n",
    "def generate_rtl_module(module_name, num_inputs, max_depth):\n",
    "    \"\"\" Generate a synthetic RTL module with random logic. \"\"\"\n",
    "    inputs = [f\"input{i}\" for i in range(num_inputs)]\n",
    "    output = \"y\"\n",
    "    expression = generate_random_expression(inputs, max_depth)\n",
    "    \n",
    "    rtl_code = f\"\"\"\n",
    "module {module_name} (\n",
    "    input {', '.join(inputs)},\n",
    "    output {output}\n",
    ");\n",
    "    assign {output} = {expression};\n",
    "endmodule\n",
    "    \"\"\"\n",
    "    return rtl_code\n",
    "\n",
    "def extract_features(rtl_code, num_inputs, max_depth):\n",
    "    \"\"\" Extract features with improved realism. \"\"\"\n",
    "    \n",
    "    gate_count = min(int(max_depth * num_inputs / random.uniform(1.5, 2.5)), 30)  \n",
    "    \n",
    "    \n",
    "    logic_depth = max_depth + random.choice([-1, 0, 0, 1])  \n",
    "    \n",
    "    gate_types = []\n",
    "    for gate in [\"AND\", \"OR\", \"NOT\", \"NAND\", \"NOR\", \"XOR\"]:\n",
    "        if gate in rtl_code:\n",
    "            gate_types.append(gate)\n",
    "    \n",
    "    return {\n",
    "        \"Module Name\": \"synthetic_module\",\n",
    "        \"Signal Name\": \"y\",\n",
    "        \"Fan-In\": num_inputs,\n",
    "        \"Fan-Out\": weighted_choice({1: 15, 2: 18, 3: 17, 4: 15, 5: 12, 6: 8, 7: 6, 8: 4, 9: 3, 10: 2}),  \n",
    "        \"Gate Count\": gate_count,\n",
    "        \"Logic Depth\": max(2, min(logic_depth, 8)),  \n",
    "        \"Gate Types\": \", \".join(gate_types)\n",
    "    }\n",
    "\n",
    "\n",
    "dataset = []\n",
    "for i in range(500):\n",
    "    num_inputs = weighted_choice({2: 5, 3: 10, 4: 15, 5: 20, 6: 20, 7: 15, 8: 8, 9: 4, 10: 2, 11: 0.5, 12: 0.5})\n",
    "    max_depth = weighted_choice({2: 18, 3: 28, 4: 25, 5: 15, 6: 8, 7: 4, 8: 2})  # Slightly adjusted\n",
    "\n",
    "    rtl_code = generate_rtl_module(f\"module_{i}\", num_inputs, max_depth)\n",
    "    features = extract_features(rtl_code, num_inputs, max_depth)\n",
    "    dataset.append(features)\n",
    "\n",
    "df = pd.DataFrame(dataset)\n",
    "\n",
    "\n",
    "print(\"Fan-In Distribution:\")\n",
    "print(df[\"Fan-In\"].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nFan-Out Distribution:\")\n",
    "print(df[\"Fan-Out\"].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nGate Count Distribution:\")\n",
    "print(df[\"Gate Count\"].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nLogic Depth Distribution:\")\n",
    "print(df[\"Logic Depth\"].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nFirst 5 Rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c0585e9-4935-43f0-9dd1-457f9173d295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to final_synthetic_rtl_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.to_csv(\"final_synthetic_rtl_dataset.csv\", index=False)\n",
    "print(\"Dataset saved to final_synthetic_rtl_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7083b1e9-b3d1-412f-8674-63e0e0cd95f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 Rows of the Dataset:\n",
      "        Module Name Signal Name  Fan-In  Fan-Out  Gate Count  Logic Depth  \\\n",
      "0  synthetic_module           y       9       10           9            2   \n",
      "1  synthetic_module           y       6        6          10            3   \n",
      "2  synthetic_module           y       8        7           9            2   \n",
      "3  synthetic_module           y       8        3          14            3   \n",
      "4  synthetic_module           y       3        6           4            2   \n",
      "\n",
      "  Gate Types  \n",
      "0  AND, NAND  \n",
      "1  AND, NAND  \n",
      "2  AND, NAND  \n",
      "3  AND, NAND  \n",
      "4        AND  \n",
      "\n",
      "Fan-In Distribution:\n",
      "Fan-In\n",
      "2      31\n",
      "3      42\n",
      "4      66\n",
      "5      89\n",
      "6     113\n",
      "7      87\n",
      "8      42\n",
      "9      18\n",
      "10      8\n",
      "11      2\n",
      "12      2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Fan-Out Distribution:\n",
      "Fan-Out\n",
      "1     79\n",
      "2     92\n",
      "3     91\n",
      "4     76\n",
      "5     47\n",
      "6     38\n",
      "7     35\n",
      "8     18\n",
      "9      9\n",
      "10    15\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Gate Count Distribution:\n",
      "Gate Count\n",
      "1      2\n",
      "2     12\n",
      "3     22\n",
      "4     34\n",
      "5     35\n",
      "6     35\n",
      "7     28\n",
      "8     40\n",
      "9     41\n",
      "10    42\n",
      "11    25\n",
      "12    29\n",
      "13    24\n",
      "14    14\n",
      "15    16\n",
      "16    18\n",
      "17    14\n",
      "18    11\n",
      "19     8\n",
      "20     5\n",
      "21     5\n",
      "22     5\n",
      "23     6\n",
      "24     3\n",
      "25     2\n",
      "26     6\n",
      "27     4\n",
      "28     3\n",
      "29     3\n",
      "30     8\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Logic Depth Distribution:\n",
      "Logic Depth\n",
      "2    102\n",
      "3    122\n",
      "4    110\n",
      "5     86\n",
      "6     41\n",
      "7     24\n",
      "8     15\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"First 5 Rows of the Dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nFan-In Distribution:\")\n",
    "print(df[\"Fan-In\"].value_counts().sort_index())\n",
    "print(\"\\nFan-Out Distribution:\")\n",
    "print(df[\"Fan-Out\"].value_counts().sort_index())\n",
    "print(\"\\nGate Count Distribution:\")\n",
    "print(df[\"Gate Count\"].value_counts().sort_index())\n",
    "print(\"\\nLogic Depth Distribution:\")\n",
    "print(df[\"Logic Depth\"].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76515788-3153-4b94-9ec7-c43324e090dd",
   "metadata": {},
   "source": [
    "## Feature Engineering  \n",
    "- Feature engineering is performed to improve the quality of input data.  \n",
    "- Key transformations include:  \n",
    "  - Encoding categorical values such as gate types into numerical features  \n",
    "  - Normalizing numerical features for consistency  \n",
    "  - Identifying and handling outliers that may affect model performance  \n",
    "- Feature correlation analysis is conducted to understand relationships between input variables and the target variable.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86892dfa-8976-4913-845f-51a9320bc607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rtl_preprocessor.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"final_synthetic_rtl_dataset.csv\")\n",
    "\n",
    "X = df.drop(columns=[\"Logic Depth\"])\n",
    "y = df[\"Logic Depth\"]\n",
    "\n",
    "categorical_features = [\"Gate Types\"]\n",
    "numerical_features = [\"Fan-In\", \"Fan-Out\", \"Gate Count\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numerical_features),  \n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features), \n",
    "    ]\n",
    ")\n",
    "\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "import joblib\n",
    "joblib.dump(preprocessor, \"rtl_preprocessor.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba4051ab-8343-4de6-916e-3845c898d73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Processed Data (X_processed): (500, 18)\n",
      "\n",
      "First 5 Rows of Processed Data (Numerical Features):\n",
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 15 stored elements and shape (5, 3)>\n",
      "  Coords\tValues\n",
      "  (0, 0)\t1.7735654185216503\n",
      "  (0, 1)\t2.636015292943297\n",
      "  (0, 2)\t-0.2874393218999412\n",
      "  (1, 0)\t0.20125565032869805\n",
      "  (1, 1)\t0.9226481867078098\n",
      "  (1, 2)\t-0.1303686541950553\n",
      "  (2, 0)\t1.2494621624573328\n",
      "  (2, 1)\t1.3509899632666815\n",
      "  (2, 2)\t-0.2874393218999412\n",
      "  (3, 0)\t1.2494621624573328\n",
      "  (3, 1)\t-0.3623771429688056\n",
      "  (3, 2)\t0.4979140166244883\n",
      "  (4, 0)\t-1.3710541178642541\n",
      "  (4, 1)\t0.9226481867078098\n",
      "  (4, 2)\t-1.0727926604243707\n",
      "\n",
      "First 5 Rows of Processed Data (Categorical Features):\n",
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 5 stored elements and shape (5, 15)>\n",
      "  Coords\tValues\n",
      "  (0, 1)\t1.0\n",
      "  (1, 1)\t1.0\n",
      "  (2, 1)\t1.0\n",
      "  (3, 1)\t1.0\n",
      "  (4, 0)\t1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Shape of Processed Data (X_processed):\", X_processed.shape)\n",
    "print(\"\\nFirst 5 Rows of Processed Data (Numerical Features):\")\n",
    "print(X_processed[:5, :len(numerical_features)])  \n",
    "\n",
    "print(\"\\nFirst 5 Rows of Processed Data (Categorical Features):\")\n",
    "print(X_processed[:5, len(numerical_features):])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aba719f-a586-4552-8be0-0fa4111ee4a2",
   "metadata": {},
   "source": [
    "## Model Training  \n",
    "- The goal is to train a machine learning model to predict logic depth based on extracted features.  \n",
    "- Steps involved:  \n",
    "  - Splitting the dataset into training (80%) and testing (20%) sets  \n",
    "  - Selecting suitable regression models for prediction  \n",
    "  - Evaluating model performance using Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE)  \n",
    "- The objective is to achieve accurate predictions while maintaining a low computational cost.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e6c7148-988c-41b5-8909-c1ac42aa139d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (400, 18)\n",
      "Shape of X_test: (100, 18)\n",
      "Shape of y_train: (400,)\n",
      "Shape of y_test: (100,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c1f9ad-1923-4e67-b0e7-eb67c352c4b7",
   "metadata": {},
   "source": [
    "## Model Evaluation  \n",
    "- The trained model is tested against the test dataset to measure performance.  \n",
    "- Evaluation metrics include:  \n",
    "  - Mean Absolute Error (MAE) to measure the average absolute difference between predicted and actual values  \n",
    "  - Root Mean Squared Error (RMSE) to account for large errors  \n",
    "  - Prediction runtime to ensure the model runs efficiently compared to synthesis-based methods  \n",
    "- A good model should have a low error rate and a fast prediction time.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67d13a3b-5f08-43c4-82a3-917a661b96a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Comparison Results:\n",
      "Random Forest:\n",
      "  MSE: 1.0432055170464851\n",
      "  R²: 0.5859638367016649\n",
      "Gradient Boosting:\n",
      "  MSE: 0.8733777883582541\n",
      "  R²: 0.6533664913644014\n",
      "XGBoost:\n",
      "  MSE: 1.3065781593322754\n",
      "  R²: 0.48143428564071655\n",
      "Support Vector Regressor:\n",
      "  MSE: 0.8679352402934981\n",
      "  R²: 0.655526575530442\n",
      "Neural Network:\n",
      "  MSE: 0.8223442120083831\n",
      "  R²: 0.6736211255721609\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Models to compare\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=42),\n",
    "    \"XGBoost\": XGBRegressor(random_state=42),\n",
    "    \"Support Vector Regressor\": SVR(),\n",
    "    \"Neural Network\": MLPRegressor(random_state=42, max_iter=1000),\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "   \n",
    "    y_pred = model.predict(X_test)\n",
    " \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "  \n",
    "    results[name] = {\"MSE\": mse, \"R²\": r2}\n",
    "\n",
    "print(\"Model Comparison Results:\")\n",
    "for name, metrics in results.items():\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  MSE: {metrics['MSE']}\")\n",
    "    print(f\"  R²: {metrics['R²']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9b8b92-56b0-4d5b-b913-89eda174a573",
   "metadata": {},
   "source": [
    "- Proceeding with Neural Network (MLP) since it performed the best.\n",
    "- It did not fully converge (indicated by the warning), meaning it might need more training iterations or tuning.\n",
    "- Fine-tuning will be done to improve its performance and address the convergence issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e141a0ad-82a8-469c-bbf8-5aac5e2c23b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'max_iter': 2000, 'solver': 'sgd'}\n",
      "Best Model - MSE: 0.7486673296899541\n",
      "Best Model - R²: 0.702862625142898\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Parameter grid \n",
    "param_grid = {\n",
    "    \"hidden_layer_sizes\": [(50,), (100,), (50, 50)],  # Different architectures\n",
    "    \"activation\": [\"relu\", \"tanh\"],  # Activation functions\n",
    "    \"solver\": [\"adam\", \"sgd\"],  # Optimization algorithms\n",
    "    \"alpha\": [0.0001, 0.001, 0.01],  # Regularization strength\n",
    "    \"max_iter\": [2000, 3000],  # Increase max iterations to avoid convergence issues\n",
    "}\n",
    "\n",
    "mlp = MLPRegressor(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=mlp, param_grid=param_grid, cv=3, scoring=\"neg_mean_squared_error\", n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_mlp = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model\n",
    "y_pred_best = best_mlp.predict(X_test)\n",
    "mse_best = mean_squared_error(y_test, y_pred_best)\n",
    "r2_best = r2_score(y_test, y_pred_best)\n",
    "\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(f\"Best Model - MSE: {mse_best}\")\n",
    "print(f\"Best Model - R²: {r2_best}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "feb19316-7782-4608-aefe-128c4120d566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance:\n",
      "Gate Count: 0.9486\n",
      "Fan-In: 0.3357\n",
      "Gate Types_AND, OR, NAND, NOR, XOR: 0.2608\n",
      "Gate Types_AND, OR, NAND, XOR: 0.0232\n",
      "Gate Types_AND, OR, NOR: 0.0063\n",
      "Fan-Out: 0.0051\n",
      "Gate Types_AND, OR, NAND, NOR: 0.0028\n",
      "Gate Types_OR: 0.0022\n",
      "Gate Types_OR, XOR: 0.0019\n",
      "Gate Types_AND, OR, XOR: 0.0014\n",
      "Gate Types_AND, OR, NAND: 0.0008\n",
      "Gate Types_AND: 0.0005\n",
      "Gate Types_OR, NOR: 0.0002\n",
      "Gate Types_AND, NAND: 0.0001\n",
      "Gate Types_OR, NOR, XOR: -0.0001\n",
      "Gate Types_AND, OR: -0.0002\n",
      "Gate Types_AND, OR, NOR, XOR: -0.0003\n",
      "Gate Types_nan: -0.0016\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "X_test_dense = X_test.toarray()\n",
    "\n",
    "result = permutation_importance(best_mlp, X_test_dense, y_test, n_repeats=10, random_state=42)\n",
    "\n",
    "importance_scores = result.importances_mean\n",
    "\n",
    "feature_names = numerical_features + list(preprocessor.named_transformers_[\"cat\"].get_feature_names_out())\n",
    "feature_importance = dict(zip(feature_names, importance_scores))\n",
    "\n",
    "sorted_feature_importance = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Feature Importance:\")\n",
    "for feature, importance in sorted_feature_importance:\n",
    "    print(f\"{feature}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fce8ec9f-6725-4f8c-878f-ece87ded11a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance After Feature Selection:\n",
      "MSE: 0.7659450428077647\n",
      "R²: 0.6960053013145877\n"
     ]
    }
   ],
   "source": [
    "\n",
    "important_features = [\"Gate Count\", \"Fan-In\", \"Gate Types_AND, OR, NAND, NOR, XOR\"]\n",
    "\n",
    "X_train_filtered = X_train[:, [feature_names.index(feature) for feature in important_features]]\n",
    "X_test_filtered = X_test[:, [feature_names.index(feature) for feature in important_features]]\n",
    "\n",
    "best_mlp.fit(X_train_filtered, y_train)\n",
    "\n",
    "y_pred_filtered = best_mlp.predict(X_test_filtered)\n",
    "mse_filtered = mean_squared_error(y_test, y_pred_filtered)\n",
    "r2_filtered = r2_score(y_test, y_pred_filtered)\n",
    "\n",
    "print(\"Performance After Feature Selection:\")\n",
    "print(f\"MSE: {mse_filtered}\")\n",
    "print(f\"R²: {r2_filtered}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6baae9f5-35fd-47cd-b428-9541ecf1e51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Results:\n",
      "MSE Scores: [0.69163875 0.67666042 0.76836335 0.66537925 0.60011743]\n",
      "R2 Scores: [0.74072622 0.71677183 0.67021617 0.7544726  0.72652323]\n",
      "Mean MSE: 0.6804 (±0.0539)\n",
      "Mean R2: 0.7217 (±0.0288)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# 5-fold cross-validation\n",
    "cv_scores_mse = -cross_val_score(best_mlp, X_processed, y, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "cv_scores_r2 = cross_val_score(best_mlp, X_processed, y, cv=5, scoring=\"r2\")\n",
    "\n",
    "\n",
    "print(\"Cross-Validation Results:\")\n",
    "print(f\"MSE Scores: {cv_scores_mse}\")\n",
    "print(f\"R2 Scores: {cv_scores_r2}\")\n",
    "print(f\"Mean MSE: {cv_scores_mse.mean():.4f} (±{cv_scores_mse.std():.4f})\")\n",
    "print(f\"Mean R2: {cv_scores_r2.mean():.4f} (±{cv_scores_r2.std():.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926162a5-7846-484c-8386-a5bac6a9b73c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
